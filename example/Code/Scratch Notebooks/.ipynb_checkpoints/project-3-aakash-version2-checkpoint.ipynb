{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest classifier, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract these items (one function for each): location, company, job title, and salary.¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Rithika suggested I merge all of the find_alls into one large function, so the code below was created with her assistance. \n",
    "\n",
    "def parse(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "        try:\n",
    "            salary = each.find('span', {'class':'no-wrap'}).text\n",
    "        except:\n",
    "            salary = 'None'\n",
    "        synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Big Data &amp; Analytics</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist - B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthcare &amp; Life Sciences - Data Scientist</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Healthcare &amp; Life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entry Level – Research Analyst/Editor/Content ...</td>\n",
       "      <td>New York, NY 10017 (Midtown area)</td>\n",
       "      <td>XG Consultants Group, Inc.</td>\n",
       "      <td>$15 an hour</td>\n",
       "      <td>Job Overview: XG Consultants Group is looking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>UBS</td>\n",
       "      <td>None</td>\n",
       "      <td>Proficient using C++, VBA, R, SAS, SQL, Oracle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Intern - Fall 2017</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>FactSet</td>\n",
       "      <td>None</td>\n",
       "      <td>Scientist and engineer. Extract, transform, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Intern - Fall 2017</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>FactSet Research Systems</td>\n",
       "      <td>None</td>\n",
       "      <td>Just the right kind of work for a passionate d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Specialist, Advanced Insights - McKinsey Solut...</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>None</td>\n",
       "      <td>As one of the fastest-growing parts of our fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Indellient</td>\n",
       "      <td>None</td>\n",
       "      <td>Big data and analytics, digital content delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning Engineer - KYC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience with Big data technologies such as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quantitative Research Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Morningstar</td>\n",
       "      <td>None</td>\n",
       "      <td>Perform ad-hoc data cleaning and statistical a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Specialist - Operations Performance, Energy In...</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>None</td>\n",
       "      <td>As one of the fastest-growing parts of our fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analyst - Energy Insights</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>None</td>\n",
       "      <td>As one of the fastest-growing parts of our fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist | NYC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Avanade</td>\n",
       "      <td>None</td>\n",
       "      <td>Design, implement and deploy ETL to load data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist - Worldwide Advanced Analytics ...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>IBM</td>\n",
       "      <td>None</td>\n",
       "      <td>The Worldwide Advanced Analytics Center of Com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0               Data Scientist - Big Data & Analytics   \n",
       "1         Healthcare & Life Sciences - Data Scientist   \n",
       "2   Entry Level – Research Analyst/Editor/Content ...   \n",
       "3                                Quantitative Analyst   \n",
       "4                     Data Science Intern - Fall 2017   \n",
       "5                     Data Science Intern - Fall 2017   \n",
       "6   Specialist, Advanced Insights - McKinsey Solut...   \n",
       "7                           Machine Learning Engineer   \n",
       "8                     Machine Learning Engineer - KYC   \n",
       "9                       Quantitative Research Analyst   \n",
       "10  Specialist - Operations Performance, Energy In...   \n",
       "11                          Analyst - Energy Insights   \n",
       "12                               Data Scientist | NYC   \n",
       "13                                     Data Scientist   \n",
       "14  Data Scientist - Worldwide Advanced Analytics ...   \n",
       "\n",
       "                              Location                     Company  \\\n",
       "0                   New York, NY 10154                        KPMG   \n",
       "1                   New York, NY 10154                        KPMG   \n",
       "2    New York, NY 10017 (Midtown area)  XG Consultants Group, Inc.   \n",
       "3                         New York, NY                         UBS   \n",
       "4   New York, NY 10016 (Gramercy area)                     FactSet   \n",
       "5   New York, NY 10016 (Gramercy area)    FactSet Research Systems   \n",
       "6    New York, NY 10022 (Midtown area)          McKinsey & Company   \n",
       "7                         New York, NY                  Indellient   \n",
       "8                         New York, NY                   Bloomberg   \n",
       "9                         New York, NY                 Morningstar   \n",
       "10   New York, NY 10022 (Midtown area)          McKinsey & Company   \n",
       "11   New York, NY 10022 (Midtown area)          McKinsey & Company   \n",
       "12                        New York, NY                     Avanade   \n",
       "13                  New York, NY 10154                        KPMG   \n",
       "14                        New York, NY                         IBM   \n",
       "\n",
       "         Salary                                           Synopsis  \n",
       "0          None  KPMG is currently seeking a Data Scientist - B...  \n",
       "1          None  KPMG is currently seeking a Healthcare & Life ...  \n",
       "2   $15 an hour  Job Overview: XG Consultants Group is looking ...  \n",
       "3          None  Proficient using C++, VBA, R, SAS, SQL, Oracle...  \n",
       "4          None  Scientist and engineer. Extract, transform, an...  \n",
       "5          None  Just the right kind of work for a passionate d...  \n",
       "6          None  As one of the fastest-growing parts of our fir...  \n",
       "7          None  Big data and analytics, digital content delive...  \n",
       "8          None  Experience with Big data technologies such as ...  \n",
       "9          None  Perform ad-hoc data cleaning and statistical a...  \n",
       "10         None  As one of the fastest-growing parts of our fir...  \n",
       "11         None  As one of the fastest-growing parts of our fir...  \n",
       "12         None  Design, implement and deploy ETL to load data ...  \n",
       "13         None  KPMG is currently seeking a Data Scientist to ...  \n",
       "14         None  The Worldwide Advanced Analytics Center of Com...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the l=New+York and the start=10. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list).\n",
    "##### Complete the following code to collect results from multiple cities and starting points.\n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = 'Washington%2C+DC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1000 results. 0 of these aren't rubbish.\n",
      "You have 2000 results. 0 of these aren't rubbish.\n",
      "You have 3000 results. 2 of these aren't rubbish.\n",
      "You have 4000 results. 2 of these aren't rubbish.\n",
      "You have 5000 results. 2 of these aren't rubbish.\n",
      "You have 6000 results. 2 of these aren't rubbish.\n",
      "You have 7000 results. 2 of these aren't rubbish.\n",
      "You have 8000 results. 4 of these aren't rubbish.\n",
      "You have 9000 results. 41 of these aren't rubbish.\n",
      "You have 10000 results. 41 of these aren't rubbish.\n",
      "You have 11000 results. 45 of these aren't rubbish.\n",
      "You have 12000 results. 52 of these aren't rubbish.\n",
      "You have 13000 results. 58 of these aren't rubbish.\n",
      "You have 14000 results. 61 of these aren't rubbish.\n",
      "You have 15000 results. 69 of these aren't rubbish.\n",
      "You have 16000 results. 69 of these aren't rubbish.\n",
      "You have 17000 results. 73 of these aren't rubbish.\n",
      "You have 18000 results. 94 of these aren't rubbish.\n",
      "You have 19000 results. 94 of these aren't rubbish.\n",
      "You have 20000 results. 94 of these aren't rubbish.\n",
      "You have 21000 results. 98 of these aren't rubbish.\n",
      "You have 22000 results. 98 of these aren't rubbish.\n",
      "You have 23000 results. 105 of these aren't rubbish.\n",
      "You have 24000 results. 105 of these aren't rubbish.\n",
      "You have 25000 results. 105 of these aren't rubbish.\n",
      "You have 26000 results. 107 of these aren't rubbish.\n",
      "You have 27000 results. 107 of these aren't rubbish.\n",
      "You have 28000 results. 107 of these aren't rubbish.\n",
      "You have 29000 results. 111 of these aren't rubbish.\n",
      "You have 30000 results. 111 of these aren't rubbish.\n",
      "You have 31000 results. 114 of these aren't rubbish.\n",
      "You have 32000 results. 114 of these aren't rubbish.\n",
      "You have 33000 results. 114 of these aren't rubbish.\n",
      "You have 34000 results. 123 of these aren't rubbish.\n",
      "You have 35000 results. 123 of these aren't rubbish.\n",
      "You have 36000 results. 123 of these aren't rubbish.\n",
      "You have 37000 results. 129 of these aren't rubbish.\n",
      "You have 38000 results. 129 of these aren't rubbish.\n",
      "You have 39000 results. 129 of these aren't rubbish.\n",
      "You have 40000 results. 133 of these aren't rubbish.\n",
      "You have 41000 results. 133 of these aren't rubbish.\n",
      "You have 42000 results. 133 of these aren't rubbish.\n",
      "You have 43000 results. 133 of these aren't rubbish.\n",
      "You have 44000 results. 133 of these aren't rubbish.\n",
      "You have 45000 results. 145 of these aren't rubbish.\n",
      "You have 46000 results. 145 of these aren't rubbish.\n",
      "You have 47000 results. 145 of these aren't rubbish.\n",
      "You have 48000 results. 154 of these aren't rubbish.\n",
      "You have 49000 results. 168 of these aren't rubbish.\n",
      "You have 50000 results. 168 of these aren't rubbish.\n",
      "You have 51000 results. 173 of these aren't rubbish.\n",
      "You have 52000 results. 173 of these aren't rubbish.\n",
      "You have 53000 results. 173 of these aren't rubbish.\n",
      "You have 54000 results. 195 of these aren't rubbish.\n",
      "You have 55000 results. 195 of these aren't rubbish.\n",
      "You have 56000 results. 195 of these aren't rubbish.\n",
      "You have 57000 results. 198 of these aren't rubbish.\n",
      "You have 58000 results. 198 of these aren't rubbish.\n",
      "You have 59000 results. 198 of these aren't rubbish.\n",
      "You have 60000 results. 199 of these aren't rubbish.\n",
      "You have 61000 results. 199 of these aren't rubbish.\n",
      "You have 62000 results. 199 of these aren't rubbish.\n",
      "You have 63000 results. 204 of these aren't rubbish.\n",
      "You have 64000 results. 204 of these aren't rubbish.\n",
      "You have 65000 results. 204 of these aren't rubbish.\n",
      "You have 66000 results. 205 of these aren't rubbish.\n",
      "You have 67000 results. 205 of these aren't rubbish.\n",
      "You have 68000 results. 208 of these aren't rubbish.\n",
      "You have 69000 results. 208 of these aren't rubbish.\n",
      "You have 70000 results. 208 of these aren't rubbish.\n",
      "You have 71000 results. 209 of these aren't rubbish.\n",
      "You have 72000 results. 209 of these aren't rubbish.\n",
      "You have 73000 results. 230 of these aren't rubbish.\n",
      "You have 74000 results. 234 of these aren't rubbish.\n",
      "You have 75000 results. 234 of these aren't rubbish.\n",
      "You have 76000 results. 235 of these aren't rubbish.\n",
      "You have 77000 results. 235 of these aren't rubbish.\n",
      "You have 78000 results. 236 of these aren't rubbish.\n",
      "You have 79000 results. 236 of these aren't rubbish.\n",
      "You have 80000 results. 236 of these aren't rubbish.\n",
      "You have 81000 results. 239 of these aren't rubbish.\n",
      "You have 82000 results. 251 of these aren't rubbish.\n",
      "You have 83000 results. 252 of these aren't rubbish.\n",
      "You have 84000 results. 258 of these aren't rubbish.\n",
      "You have 85000 results. 258 of these aren't rubbish.\n",
      "You have 86000 results. 258 of these aren't rubbish.\n",
      "You have 87000 results. 260 of these aren't rubbish.\n",
      "You have 88000 results. 260 of these aren't rubbish.\n",
      "You have 89000 results. 264 of these aren't rubbish.\n",
      "You have 90000 results. 264 of these aren't rubbish.\n",
      "You have 91000 results. 266 of these aren't rubbish.\n",
      "You have 92000 results. 266 of these aren't rubbish.\n",
      "You have 93000 results. 266 of these aren't rubbish.\n",
      "You have 94000 results. 277 of these aren't rubbish.\n",
      "You have 95000 results. 277 of these aren't rubbish.\n",
      "You have 96000 results. 277 of these aren't rubbish.\n",
      "You have 97000 results. 292 of these aren't rubbish.\n",
      "You have 98000 results. 292 of these aren't rubbish.\n",
      "You have 99000 results. 292 of these aren't rubbish.\n",
      "You have 100000 results. 295 of these aren't rubbish.\n",
      "You have 101000 results. 295 of these aren't rubbish.\n",
      "You have 102000 results. 295 of these aren't rubbish.\n",
      "You have 103000 results. 295 of these aren't rubbish.\n",
      "You have 104000 results. 300 of these aren't rubbish.\n",
      "You have 105000 results. 300 of these aren't rubbish.\n",
      "You have 106000 results. 300 of these aren't rubbish.\n",
      "You have 107000 results. 301 of these aren't rubbish.\n",
      "You have 108000 results. 301 of these aren't rubbish.\n",
      "You have 109000 results. 301 of these aren't rubbish.\n",
      "You have 110000 results. 303 of these aren't rubbish.\n",
      "You have 111000 results. 303 of these aren't rubbish.\n",
      "You have 112000 results. 303 of these aren't rubbish.\n",
      "You have 113000 results. 307 of these aren't rubbish.\n",
      "You have 114000 results. 307 of these aren't rubbish.\n",
      "You have 115000 results. 307 of these aren't rubbish.\n",
      "You have 116000 results. 331 of these aren't rubbish.\n",
      "You have 117000 results. 331 of these aren't rubbish.\n",
      "You have 118000 results. 331 of these aren't rubbish.\n",
      "You have 119000 results. 352 of these aren't rubbish.\n",
      "You have 120000 results. 352 of these aren't rubbish.\n",
      "You have 121000 results. 352 of these aren't rubbish.\n",
      "You have 122000 results. 352 of these aren't rubbish.\n",
      "You have 123000 results. 354 of these aren't rubbish.\n",
      "You have 124000 results. 354 of these aren't rubbish.\n",
      "You have 125000 results. 373 of these aren't rubbish.\n",
      "You have 126000 results. 373 of these aren't rubbish.\n",
      "You have 127000 results. 373 of these aren't rubbish.\n",
      "You have 128000 results. 382 of these aren't rubbish.\n",
      "You have 129000 results. 382 of these aren't rubbish.\n",
      "You have 130000 results. 382 of these aren't rubbish.\n",
      "You have 131000 results. 382 of these aren't rubbish.\n",
      "You have 132000 results. 382 of these aren't rubbish.\n",
      "You have 133000 results. 382 of these aren't rubbish.\n",
      "You have 134000 results. 382 of these aren't rubbish.\n",
      "You have 135000 results. 382 of these aren't rubbish.\n",
      "You have 136000 results. 382 of these aren't rubbish.\n",
      "You have 137000 results. 408 of these aren't rubbish.\n",
      "You have 138000 results. 429 of these aren't rubbish.\n",
      "You have 139000 results. 429 of these aren't rubbish.\n",
      "You have 140000 results. 429 of these aren't rubbish.\n",
      "You have 141000 results. 429 of these aren't rubbish.\n",
      "You have 142000 results. 429 of these aren't rubbish.\n",
      "You have 143000 results. 446 of these aren't rubbish.\n",
      "You have 144000 results. 446 of these aren't rubbish.\n",
      "You have 145000 results. 446 of these aren't rubbish.\n",
      "You have 146000 results. 469 of these aren't rubbish.\n",
      "You have 147000 results. 469 of these aren't rubbish.\n",
      "You have 148000 results. 469 of these aren't rubbish.\n",
      "You have 149000 results. 470 of these aren't rubbish.\n",
      "You have 150000 results. 471 of these aren't rubbish.\n",
      "You have 151000 results. 471 of these aren't rubbish.\n",
      "You have 152000 results. 475 of these aren't rubbish.\n",
      "You have 153000 results. 475 of these aren't rubbish.\n",
      "You have 154000 results. 475 of these aren't rubbish.\n",
      "You have 155000 results. 475 of these aren't rubbish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 156000 results. 475 of these aren't rubbish.\n",
      "You have 157000 results. 476 of these aren't rubbish.\n",
      "You have 158000 results. 476 of these aren't rubbish.\n",
      "You have 159000 results. 476 of these aren't rubbish.\n",
      "You have 160000 results. 476 of these aren't rubbish.\n",
      "You have 161000 results. 476 of these aren't rubbish.\n",
      "You have 162000 results. 476 of these aren't rubbish.\n",
      "You have 163000 results. 476 of these aren't rubbish.\n",
      "You have 164000 results. 477 of these aren't rubbish.\n",
      "You have 165000 results. 488 of these aren't rubbish.\n",
      "You have 166000 results. 497 of these aren't rubbish.\n",
      "You have 167000 results. 501 of these aren't rubbish.\n",
      "You have 168000 results. 501 of these aren't rubbish.\n",
      "You have 169000 results. 501 of these aren't rubbish.\n",
      "You have 170000 results. 504 of these aren't rubbish.\n",
      "You have 171000 results. 506 of these aren't rubbish.\n",
      "You have 172000 results. 506 of these aren't rubbish.\n",
      "You have 173000 results. 506 of these aren't rubbish.\n",
      "You have 174000 results. 506 of these aren't rubbish.\n",
      "You have 175000 results. 506 of these aren't rubbish.\n",
      "You have 176000 results. 509 of these aren't rubbish.\n",
      "You have 177000 results. 516 of these aren't rubbish.\n",
      "You have 178000 results. 516 of these aren't rubbish.\n",
      "You have 179000 results. 516 of these aren't rubbish.\n",
      "You have 180000 results. 516 of these aren't rubbish.\n",
      "You have 181000 results. 516 of these aren't rubbish.\n",
      "You have 182000 results. 521 of these aren't rubbish.\n",
      "You have 183000 results. 521 of these aren't rubbish.\n",
      "You have 184000 results. 521 of these aren't rubbish.\n",
      "You have 185000 results. 532 of these aren't rubbish.\n",
      "You have 186000 results. 532 of these aren't rubbish.\n",
      "You have 187000 results. 532 of these aren't rubbish.\n",
      "You have 188000 results. 533 of these aren't rubbish.\n",
      "You have 189000 results. 533 of these aren't rubbish.\n",
      "You have 190000 results. 533 of these aren't rubbish.\n",
      "You have 191000 results. 534 of these aren't rubbish.\n",
      "You have 192000 results. 534 of these aren't rubbish.\n",
      "You have 193000 results. 534 of these aren't rubbish.\n",
      "You have 194000 results. 547 of these aren't rubbish.\n",
      "You have 195000 results. 547 of these aren't rubbish.\n",
      "You have 196000 results. 547 of these aren't rubbish.\n",
      "You have 197000 results. 581 of these aren't rubbish.\n",
      "You have 198000 results. 581 of these aren't rubbish.\n",
      "You have 199000 results. 581 of these aren't rubbish.\n"
     ]
    }
   ],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 2000 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "i = 0\n",
    "results = []\n",
    "df_more = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY, \n",
    "    'Charlottesville', 'Richmond', 'Baltimore', 'Harrisonburg', 'San+Antonio', 'San+Diego', 'San+Jose'\n",
    "    'Austin', 'Jacksonville', 'Indianapolis', 'Columbus', 'Fort+Worth', 'Charlotte', 'Detroit', 'El+Paso', \n",
    "    'Memphis', 'Boston', 'Nashville', 'Louisville', 'Milwaukee', 'Las+Vegas', 'Albuquerque', 'Tucson', \n",
    "    'Fresno', 'Sacramento', 'Long+Beach', 'Mesa', 'Virginia+Beach', 'Norfolk', 'Atlanta', 'Colorado+Springs',\n",
    "    'Raleigh', 'Omaha', 'Oakland', 'Tulsa', 'Minneapolis', 'Cleveland', 'Wichita', 'Arlington', 'New+Orleans', \n",
    "    'Bakersfield', 'Tampa', 'Honolulu', 'Anaheim', 'Aurora', 'Santa+Ana', 'Riverside', 'Corpus+Christi', 'Pittsburgh', \n",
    "    'Lexington', 'Anchorage', 'Cincinnati', 'Baton+Rouge', 'Chesapeake', 'Alexandria', 'Fairfax', 'Herndon',\n",
    "    'Reston', 'Roanoke']):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        url = url_template.format(city, start)\n",
    "        # Append to the full set of results\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "            except:\n",
    "                title = None\n",
    "            try:\n",
    "                location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "            except:\n",
    "                location = None\n",
    "            try: \n",
    "                company = each.find(class_='company').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = None\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'no-wrap'}).text\n",
    "            except:\n",
    "                salary = None\n",
    "            try:\n",
    "                synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "            except:\n",
    "                synopsis = None\n",
    "            df_more = df_more.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:  # Ram helped me build this counter to see how many. You can visibly see Ram's vernacular in the print statements.\n",
    "                print('You have ' + str(i) + ' results. ' + str(df_more.dropna().drop_duplicates().shape[0]) + \" of these aren't rubbish.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more.to_csv('Indeed_Project_3_df_more_long_not_cleaned.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Title           Location                 Company  \\\n",
      "0            Systems Administrator         Forest, VA  Innerspec Technologies   \n",
      "1          Environmental Scientist     Blacksburg, VA             CyberCoders   \n",
      "2                   Senior Manager      United States                Exponent   \n",
      "3  Software Engineering Specialist  Roanoke, VA 24019        General Electric   \n",
      "4       Sr Staff Software Engineer  Roanoke, VA 24019        General Electric   \n",
      "\n",
      "  Salary                                           Synopsis  \n",
      "0   None  Manage backup and restore services to ensure t...  \n",
      "1   None  Environmental Scientist If you are an Environm...  \n",
      "2   None  Providing case management, data processing, an...  \n",
      "3   None  You will work with a group of energized and fo...  \n",
      "4   None  Architects, Data Scientists, Businesses & Prod...  \n",
      "(199055, 5)\n",
      "(199055, 5)\n",
      "(581, 5)\n"
     ]
    }
   ],
   "source": [
    "print (df_more.head())\n",
    "print (df_more.shape)\n",
    "print (df_more[df_more.Salary != 'None'].shape)\n",
    "df_more = df_more[df_more.Salary != 'None'].drop_duplicates().dropna()\n",
    "print (df_more.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>$50,000 - $100,000 a year</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Data Scientist – Marketing Analytics</td>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>Enterprise Select</td>\n",
       "      <td>$125,000 a year</td>\n",
       "      <td>We are currently looking for an experienced Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Authority</td>\n",
       "      <td>$55,000 - $60,000 a year</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL 60606 (Loop area)</td>\n",
       "      <td>ICJIA</td>\n",
       "      <td>$55,000 - $60,000 a year</td>\n",
       "      <td>(3) analyzing qualitative and quantitative dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>Data Scientist (Python, R, AWS, Azure)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>$85,000 - $125,000 a year</td>\n",
       "      <td>Our startup client working on risk and fraud d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title                       Location  \\\n",
       "2724                Environmental Consultant            Nashville, TN 37220   \n",
       "8054    Data Scientist – Marketing Analytics  Chicago, IL 60601 (Loop area)   \n",
       "8194                        Research Analyst                    Chicago, IL   \n",
       "8197                        Research Analyst  Chicago, IL 60606 (Loop area)   \n",
       "8234  Data Scientist (Python, R, AWS, Azure)                    Chicago, IL   \n",
       "\n",
       "                                              Company  \\\n",
       "2724                                 LP Environmental   \n",
       "8054                                Enterprise Select   \n",
       "8194  Illinois Criminal Justice Information Authority   \n",
       "8197                                            ICJIA   \n",
       "8234                            Workbridge Associates   \n",
       "\n",
       "                         Salary  \\\n",
       "2724  $50,000 - $100,000 a year   \n",
       "8054            $125,000 a year   \n",
       "8194   $55,000 - $60,000 a year   \n",
       "8197   $55,000 - $60,000 a year   \n",
       "8234  $85,000 - $125,000 a year   \n",
       "\n",
       "                                               Synopsis  \n",
       "2724  We are seeking a mid-level Environmental Scien...  \n",
       "8054  We are currently looking for an experienced Da...  \n",
       "8194  Produce analyses of crime trends and provide d...  \n",
       "8197  (3) analyzing qualitative and quantitative dat...  \n",
       "8234  Our startup client working on risk and fraud d...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more = df_more[df_more.Salary.str.contains(\"hour\") == False]\n",
    "df_more = df_more[df_more.Salary.str.contains(\"month\") == False]\n",
    "print (df_more.shape)\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "def salary_stripper(dataframe, column):\n",
    "    dataframe[str(column)] = dataframe[str(column)].replace({'\\$':''}, regex = True)\n",
    "    dataframe[str(column)].replace(regex=True,inplace=True,to_replace=r'\\D',value=r' ')\n",
    "    dataframe[str(column)] = dataframe[str(column)].str.replace(' ',',')\n",
    "    dataframe = dataframe.join(dataframe[str(column)].str.split(',,,', 1, expand=True).rename(columns={0:'Low', 1:'High'}))\n",
    "    dataframe['Low'] = dataframe['Low'].str.replace(',','')\n",
    "    dataframe['Low'] = dataframe['Low'].astype('float64')\n",
    "    dataframe.drop(str(column), axis=1, inplace=True)\n",
    "    dataframe['High'] = dataframe['High'].str.replace(',','')\n",
    "    dataframe['High'] = dataframe['High'].apply(pd.to_numeric)\n",
    "    dataframe['Average'] = dataframe[['Low', 'High']].mean(axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_more = salary_stripper(df_more, 'Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17086</th>\n",
       "      <td>Senior Data Scientist Healthcare</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>Senior Data Scientist - Healthcare. Reporting ...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17252</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Data Scientist Qualifications:. Data Scientist...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17287</th>\n",
       "      <td>Predictive Analytics (Machine Learning)</td>\n",
       "      <td>Wilmington, DE</td>\n",
       "      <td>Kennedy Unlimited Inc, Professional Staffing</td>\n",
       "      <td>Salary 130K to 140K We are assisting our Clien...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>Data Scientist/Machine Learning Specialist</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>A leading healthcare analytical team, one of t...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17406</th>\n",
       "      <td>NMR Spectroscopist</td>\n",
       "      <td>West Point, PA</td>\n",
       "      <td>EPM Scientific</td>\n",
       "      <td>Scientist | Structure Elucidation*. Excellent ...</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17421</th>\n",
       "      <td>Data Scientist/Optimization Engineer</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>In this role you will be extracting power plan...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>112500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17451</th>\n",
       "      <td>Research Scientist (Gene Therapy, Molecular Cl...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Apex Life Sciences</td>\n",
       "      <td>Analyze and interpret the results including st...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17459</th>\n",
       "      <td>Machine Learning Researcher</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Experience with Data Mining. This agency, spec...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>115000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17467</th>\n",
       "      <td>Quant Research Analyst</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>3coast</td>\n",
       "      <td>Experience in data and time series analysis st...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17481</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Winston Fox</td>\n",
       "      <td>In this role, you will examine global markets,...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title          Location  \\\n",
       "17086                   Senior Data Scientist Healthcare  Philadelphia, PA   \n",
       "17252                                     Data Scientist  Philadelphia, PA   \n",
       "17287            Predictive Analytics (Machine Learning)    Wilmington, DE   \n",
       "17376         Data Scientist/Machine Learning Specialist  Philadelphia, PA   \n",
       "17406                                 NMR Spectroscopist    West Point, PA   \n",
       "17421               Data Scientist/Optimization Engineer  Philadelphia, PA   \n",
       "17451  Research Scientist (Gene Therapy, Molecular Cl...  Philadelphia, PA   \n",
       "17459                        Machine Learning Researcher  Philadelphia, PA   \n",
       "17467                             Quant Research Analyst  Philadelphia, PA   \n",
       "17481                               Quantitative Analyst  Philadelphia, PA   \n",
       "\n",
       "                                            Company  \\\n",
       "17086                                       Harnham   \n",
       "17252                       Smith Hanley Associates   \n",
       "17287  Kennedy Unlimited Inc, Professional Staffing   \n",
       "17376                            Jobspring Partners   \n",
       "17406                                EPM Scientific   \n",
       "17421                            Jobspring Partners   \n",
       "17451                            Apex Life Sciences   \n",
       "17459                            Jobspring Partners   \n",
       "17467                                        3coast   \n",
       "17481                                   Winston Fox   \n",
       "\n",
       "                                                Synopsis       Low      High  \\\n",
       "17086  Senior Data Scientist - Healthcare. Reporting ...  170000.0       NaN   \n",
       "17252  Data Scientist Qualifications:. Data Scientist...  120000.0  140000.0   \n",
       "17287  Salary 130K to 140K We are assisting our Clien...  130000.0  140000.0   \n",
       "17376  A leading healthcare analytical team, one of t...  100000.0  160000.0   \n",
       "17406  Scientist | Structure Elucidation*. Excellent ...  115000.0  145000.0   \n",
       "17421  In this role you will be extracting power plan...  100000.0  125000.0   \n",
       "17451  Analyze and interpret the results including st...   50000.0       NaN   \n",
       "17459  Experience with Data Mining. This agency, spec...  100000.0  130000.0   \n",
       "17467  Experience in data and time series analysis st...  150000.0  250000.0   \n",
       "17481  In this role, you will examine global markets,...  100000.0  110000.0   \n",
       "\n",
       "        Average  \n",
       "17086  170000.0  \n",
       "17252  130000.0  \n",
       "17287  135000.0  \n",
       "17376  130000.0  \n",
       "17406  130000.0  \n",
       "17421  112500.0  \n",
       "17451   50000.0  \n",
       "17459  115000.0  \n",
       "17467  200000.0  \n",
       "17481  105000.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more = df_more.join(df_more['Location'].str.split(',', 1, expand=True).rename(columns={0:'City', 1:'State'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN 37220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Data Scientist – Marketing Analytics</td>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>Enterprise Select</td>\n",
       "      <td>We are currently looking for an experienced Da...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60601 (Loop area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Authority</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL 60606 (Loop area)</td>\n",
       "      <td>ICJIA</td>\n",
       "      <td>(3) analyzing qualitative and quantitative dat...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60606 (Loop area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>Data Scientist (Python, R, AWS, Azure)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Our startup client working on risk and fraud d...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title                       Location  \\\n",
       "2724                Environmental Consultant            Nashville, TN 37220   \n",
       "8054    Data Scientist – Marketing Analytics  Chicago, IL 60601 (Loop area)   \n",
       "8194                        Research Analyst                    Chicago, IL   \n",
       "8197                        Research Analyst  Chicago, IL 60606 (Loop area)   \n",
       "8234  Data Scientist (Python, R, AWS, Azure)                    Chicago, IL   \n",
       "\n",
       "                                              Company  \\\n",
       "2724                                 LP Environmental   \n",
       "8054                                Enterprise Select   \n",
       "8194  Illinois Criminal Justice Information Authority   \n",
       "8197                                            ICJIA   \n",
       "8234                            Workbridge Associates   \n",
       "\n",
       "                                               Synopsis       Low      High  \\\n",
       "2724  We are seeking a mid-level Environmental Scien...   50000.0  100000.0   \n",
       "8054  We are currently looking for an experienced Da...  125000.0       NaN   \n",
       "8194  Produce analyses of crime trends and provide d...   55000.0   60000.0   \n",
       "8197  (3) analyzing qualitative and quantitative dat...   55000.0   60000.0   \n",
       "8234  Our startup client working on risk and fraud d...   85000.0  125000.0   \n",
       "\n",
       "       Average       City                  State  \n",
       "2724   75000.0  Nashville               TN 37220  \n",
       "8054  125000.0    Chicago   IL 60601 (Loop area)  \n",
       "8194   57500.0    Chicago                     IL  \n",
       "8197   57500.0    Chicago   IL 60606 (Loop area)  \n",
       "8234  105000.0    Chicago                     IL  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "df_more.to_csv('Indeed_Project_3_df_more_long.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the job titles.\n",
    "- Build a new random forest model with location and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the job descriptions. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
